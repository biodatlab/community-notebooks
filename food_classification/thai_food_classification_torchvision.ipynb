{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Thai Food Classification using Pretrained Model CNN from Torchvision\n",
        "\n",
        "- This notebook uses `torchvision` to load pretrained model (ResNet34) to fine-tune Thai food classification model (Transfer Learning)\n",
        "- Reference: https://github.com/udacity/deep-learning-v2-pytorch/blob/master/transfer-learning/Transfer_Learning_Solution.ipynb"
      ],
      "metadata": {
        "id": "YvvCl7r7YkdD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E6KMqNQX_yT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path as op\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/GemmyTheGeek/FoodyDudy.git # download data from FuodyDudy git"
      ],
      "metadata": {
        "id": "x-cOIKb4ZUt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food_list = [\n",
        "    'green_curry', 'tepo_curry', 'liang_curry', 'taohoo_moosup', 'mara_yadsai',\n",
        "    'masaman', 'orange_curry', 'cashew_chicken', 'omelette', 'sunny_side_up',\n",
        "    'palo_egg', 'sil_egg', 'nun_banana', 'kua_gai', 'cabbage_fish_sauce',\n",
        "    'river_prawn', 'shrimp_ob_woonsen', 'kanom_krok', 'mango_sticky_rice', 'kao_kamoo',\n",
        "    'kao_klook_kapi', 'kaosoi', 'kao_pad', 'kao_pad_shrimp', 'chicken_rice',\n",
        "    'kao_mok_gai', 'tom_ka_gai', 'tom_yum_kung', 'tod_mun', 'poh_pia',\n",
        "    'pak_boong_fai_daeng', 'padthai', 'pad_krapao', 'pad_si_ew', 'pad_fakthong',\n",
        "    'eggplant_stirfry', 'pad_hoi_lai', 'foithong', 'panaeng', 'yum_tua_ploo',\n",
        "    'yum_woonsen', 'larb_moo', 'pumpkin_custard', 'sakoo_sai_moo', 'somtam',\n",
        "    'moopoing','satay', 'hor_mok'\n",
        "]\n",
        "id2food = {i: f for i, f in enumerate(food_list)}\n",
        "train_on_gpu = torch.cuda.is_available() # check if CUDA is available\n",
        "n_classes = len(food_list)"
      ],
      "metadata": {
        "id": "T-1s2mf8bSID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"FoodyDudy/images/\"\n",
        "train_dir = op.join(root_dir, \"train\")\n",
        "val_dir = op.join(root_dir, \"valid\")\n",
        "test_dir = op.join(root_dir, \"test\")\n",
        "\n",
        "# optional: you can use `albumentations` library for augmentations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "val_data = datasets.ImageFolder(val_dir, transform=val_transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=val_transform)"
      ],
      "metadata": {
        "id": "_gyllAU7YM8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "                                           num_workers=0, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size,\n",
        "                                         num_workers=0, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "                                          num_workers=0, shuffle=True)  # set shuffle True just to see random photos"
      ],
      "metadata": {
        "id": "SXr5xWvsbbCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "# display 16 images with 2 rows, 8 columns\n",
        "for idx in np.arange(16):\n",
        "    ax = fig.add_subplot(2, 8, idx + 1, xticks=[], yticks=[]) # plot image\n",
        "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
        "    ax.set_title(id2food[int(labels[idx])]) # set title"
      ],
      "metadata": {
        "id": "qO8GR2Y6bfLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet34 = models.resnet34(pretrained=True)\n",
        "print(resnet34)"
      ],
      "metadata": {
        "id": "A791m3ILYq2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for param in resnet34.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "n_inputs = 512\n",
        "resnet34.fc = nn.Linear(n_inputs, n_classes)\n",
        "\n",
        "if train_on_gpu:\n",
        "    resnet34.cuda()"
      ],
      "metadata": {
        "id": "AgNIC3JbZAEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet34.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "71qC_IC4a-fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 4 # number of epochs to train the model\n",
        "print_every_iter = 100 # print every 100 iterations (100 * batch size)\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "\n",
        "    resnet34.train()\n",
        "    # model by default is set to train\n",
        "    for batch_i, (data, target) in enumerate(train_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        output = resnet34(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        if batch_i % print_every_iter == (print_every_iter - 1):  # print training loss every specified number of mini-batches\n",
        "            print('Epoch %d, Batch %d loss: %.16f' %\n",
        "                  (epoch, batch_i + 1, train_loss / 20))\n",
        "            train_loss = 0.0"
      ],
      "metadata": {
        "id": "DRgI8m9GbKz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can test predicting on a sample batch from `test_loader`"
      ],
      "metadata": {
        "id": "QjUtgJwucUBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet34.eval()\n",
        "images, labels = next(iter(test_loader))\n",
        "if train_on_gpu:\n",
        "    images = images.cuda()\n",
        "\n",
        "# get sample outputs\n",
        "preds = resnet34(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds_tensor = torch.max(preds, 1)\n",
        "preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())"
      ],
      "metadata": {
        "id": "zCAOrkL2cJpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# comparing labels to predictions\n",
        "print(\"Labels:      \", labels.tolist())\n",
        "print(\"Predictions: \", preds.tolist())"
      ],
      "metadata": {
        "id": "PnJiaGeR4hnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred, y_true = [], []\n",
        "for images, labels in test_loader:\n",
        "    if train_on_gpu:\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "    pred = resnet34(images).argmax(dim=1)\n",
        "    y_pred.extend(pred.cpu().tolist())\n",
        "    y_true.extend(labels.cpu().tolist())\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "d--t-oTgccZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize test sample"
      ],
      "metadata": {
        "id": "Rwt-JAgw3r69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(test_loader))\n",
        "if train_on_gpu:\n",
        "    images = images.cuda()\n",
        "preds = resnet34(images).argmax(dim=1)\n",
        "preds = np.squeeze(preds.numpy()) if not train_on_gpu else np.squeeze(preds.cpu().numpy())\n",
        "\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "# display 16 images with 2 rows, 8 columns\n",
        "for idx in np.arange(16):\n",
        "    ax = fig.add_subplot(2, 8, idx + 1, xticks=[], yticks=[]) # plot image\n",
        "    images_np = images.cpu().numpy() if train_on_gpu else images.numpy()\n",
        "    plt.imshow(np.transpose(images_np[idx], (1, 2, 0)))\n",
        "    ax.set_title(\n",
        "        id2food[int(preds[idx])],\n",
        "        color=(\"green\" if preds[idx] == labels[idx].item() else \"red\")\n",
        "    ) # set title with color green if the prediction is equal to label else red"
      ],
      "metadata": {
        "id": "EQ_zI9m_b8eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some limitations for pure Pytorch code:\n",
        "- Need to specify if we want to move the data/model to GPU\n",
        "- The training is lengthly similar to regular Pytorch code\n",
        "\n",
        "Alternative libraries: Pytorch Lightning, Ignite"
      ],
      "metadata": {
        "id": "27JaA3orcbp0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BTrYq1eWiRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}