{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RciacfiQY1O"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_YNlydvQY1S"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install pythainlp\n",
        "!pip install emoji\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isHdsGv1eZzD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a directory for the downloaded dataset.\n",
        "dataset_name = \"wongnai-dataset\"\n",
        "os.makedirs(dataset_name, exist_ok=True)\n",
        "\n",
        "# Download the dataset from github.\n",
        "!wget https://github.com/wongnai/wongnai-corpus/raw/master/review/review_dataset.zip\n",
        "\n",
        "# Unzip the dataset.\n",
        "!unzip review_dataset.zip -d wongnai-dataset # for linux\n",
        "# !tar -xzvf review_dataset.zip -C wongnai-dataset # for windows\n",
        "\n",
        "# Remove the zip file.\n",
        "!rm review_dataset.zip\n",
        "# Remove the unrelated __MACOSX folder.\n",
        "!rm -r wongnai-dataset/__MACOSX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "043qPOoDnqtl"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jU8RThTQY1V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the train dataset.\n",
        "train_df = pd.read_csv(\"wongnai-dataset/w_review_train.csv\",\n",
        "    sep=\";\",\n",
        "    names=[\"review\", \"rating\"],\n",
        "    header=None\n",
        ")\n",
        "# Remove duplicate rows from training dataset.\n",
        "train_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Read the test dataset.\n",
        "test_df = pd.read_csv(\"wongnai-dataset/test_file.csv\", sep=\";\")\n",
        "test_df[\"rating\"] = 0 # Fill a dummy rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "griYLwKKQY1W"
      },
      "outputs": [],
      "source": [
        "# Preview the percentage of each rating on training dataset.\n",
        "n_samples = len(train_df)\n",
        "print(f\"Total training samples: {n_samples}\")\n",
        "train_df.rating.value_counts() / n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymI7A_O6QY1W"
      },
      "outputs": [],
      "source": [
        "# Get each dataset components.\n",
        "X_train, y_train = train_df[\"review\"], train_df[\"rating\"]\n",
        "X_test = test_df[\"review\"]\n",
        "\n",
        "print(f\"Total train samples: {len(X_train)}\")\n",
        "print(f\"Total test samples: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIMWMIxPntbE"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYy4N1LBQY1X"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.svm import LinearSVC\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "\n",
        "# Create a pipeline for text classification.\n",
        "rating_classifier = Pipeline([\n",
        "    (\"vect\", CountVectorizer(tokenizer=word_tokenize, ngram_range=(1, 2))),\n",
        "    (\"tfidf\", TfidfTransformer()),\n",
        "    (\"clf\", LinearSVC()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdLCHHAJiLW8"
      },
      "outputs": [],
      "source": [
        "# Train a classifier.\n",
        "rating_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR3b4imtnxkb"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frgIyG05QY1X"
      },
      "outputs": [],
      "source": [
        "# Predict test dataset to get rating predictions\n",
        "rating_predictions = rating_classifier.predict(X_test)\n",
        "\n",
        "# Create a prediction result dataframe.\n",
        "submit_df = pd.DataFrame({\n",
        "    \"review\": test_df.review,\n",
        "    \"rating\": rating_predictions\n",
        "})\n",
        "# See the first 10 results\n",
        "pd.set_option('display.max_colwidth', 150) # Make long text easier to read\n",
        "submit_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLIXdiiGlWPV"
      },
      "outputs": [],
      "source": [
        "# Define function for later predict.\n",
        "def predict_rating(review: str) -> str:\n",
        "  \"\"\"Predict a rating of a given text review.\"\"\"\n",
        "  predictions = rating_classifier.predict([review])\n",
        "  prediction = predictions[0]\n",
        "  return str(prediction)\n",
        "\n",
        "# Try bad rating prediction\n",
        "bad_review_text = \"อาหารแย่มากๆ ไม่อร่อยเลย บรรยากาศร้านสกปรกและไม่ดูเอาจริงในราคาที่แพงมาก พนักงานบริการก็ไม่ใส่ใจเลย ไม่แนะนำเลยค่ะ อย่าไปเสียเวลาและเงินกับร้านนี้\"\n",
        "predicted_rating = predict_rating(bad_review_text)\n",
        "\n",
        "print(f\"Review: {bad_review_text}\")\n",
        "print(f\"Predicted rating: {predicted_rating}\")\n",
        "\n",
        "# Try good rating prediction\n",
        "good_review_text = \"อาหารอร่อยมากค่ะ! บรรยากาศร้านสวยงามและเป็นกันเอง พนักงานบริการดีมาก ไม่เคยผิดหวังเลย ขอแนะนำเมนูทานเล่นและสเต็กที่นี่นะคะ สั่งมาทานหลายครั้งแล้วครับ ถ้ามีโอกาสจะกลับมาใหม่แน่นอน!\"\n",
        "predicted_rating = predict_rating(good_review_text)\n",
        "\n",
        "print(f\"Review: {good_review_text}\")\n",
        "print(f\"Predicted rating: {predicted_rating}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9b0DOi-jLcM"
      },
      "source": [
        "# Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btrVDquvjLKi"
      },
      "outputs": [],
      "source": [
        "from gradio.components import Textbox, Label\n",
        "from gradio import Interface\n",
        "\n",
        "# Create a gradio interface\n",
        "rating_interface = Interface(\n",
        "    fn=predict_rating,\n",
        "    inputs=Textbox(label=\"Review\"),\n",
        "    outputs=Label(label=\"Predicted Rating\")\n",
        ")\n",
        "# Launch the webapp\n",
        "rating_interface.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}